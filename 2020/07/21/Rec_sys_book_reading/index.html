<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>《深度学习推荐系统》阅读 WIP | Amyy Lewis</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="life tech"><meta name="description" content="Fledgling Developer | Backpacker | Doing all I can to be a better girl."><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://amylewis.github.io/2020/07/21/Rec_sys_book_reading/index.html"><link rel="icon" type="image/png" href="http://oo12ugek5.bkt.clouddn.com/blog/images/favicon.ico" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="AmyLewis" type="application/atom+xml"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-66043212-2"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-66043212-2")</script><link rel="stylesheet" href="/scss/views/page/post.css"><meta name="generator" content="Hexo 6.3.0"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(https://user-images.githubusercontent.com/3325198/52893052-6d1d2d80-31d3-11e9-91c2-736385c3278a.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="AmyLewis" alt="AmyLewis"><img src="https://user-images.githubusercontent.com/3325198/52892707-fc284680-31cf-11e9-932d-e3cde3ef02f3.png" alt="AmyLewis"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="https://user-images.githubusercontent.com/3325198/89426746-0dbb3080-d76d-11ea-8038-369a0186a4cf.jpg" alt="《深度学习推荐系统》阅读 WIP"></div><header class="post__info"><h1 class="post__title">《深度学习推荐系统》阅读 WIP</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a target="_blank" rel="noopener" href="https://www.github.com/amylewis">amy</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2020-07-21</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/tech/">Tech</a></li><li class="mark__item"><a href="/tags/reading/">Reading</a></li></ul></div></div></header><div class="post__content"><p><strong>Table of content:</strong></p><div class="toc"><ul><li><a href="#about">About</a></li><li><a href="#shen-du-xue-xi-tui-jian-xi-tong">《深度学习推荐系统》</a><ul><li><a href="#tui-jian-xi-tong-de-ji-zhu-jia-gou">推荐系统的技术架构</a></li><li><a href="#tui-jian-xi-tong-de-jin-hua">推荐系统的进化</a></li><li><a href="#shen-du-xue-xi-zai-tui-jian-xi-tong-zhong-de-ying-yong">深度学习在推荐系统中的应用</a></li><li><a href="#embedding-ji-zhu-zai-tui-jian-xi-tong-zhong-de-ying-yong">Embedding 技术在推荐系统中的应用</a><ul><li><a href="#word2vec-jing-dian-de-embedding-fang-fa">Word2vec，经典的 Embedding 方法</a></li><li><a href="#item2vec">Item2vec</a></li><li><a href="#graph-embedding">Graph Embedding</a></li></ul></li><li><a href="#duo-jiao-du-shen-shi-tui-jian-xi-tong">多角度审视推荐系统</a><ul><li><a href="#te-zheng-gong-cheng">特征工程</a></li><li><a href="#zhao-hui-ceng-he-pai-xu">召回层和排序</a></li><li><a href="#parameter-server">Parameter Server</a></li><li><a href="#ru-he-zeng-jia-shi-shi-xing">如何增加实时性</a></li></ul></li><li><a href="#tui-jian-xi-tong-de-ping-gu">推荐系统的评估</a><ul><li><a href="#netflix-tui-jian-xi-tong-mo-xing-de-kuai-su-xian-shang-ping-gu-fang-fa-interleaving-https-zhuanlan-zhihu-com-p-68509372">Netflix 推荐系统模型的快速线上评估方法——Interleaving</a></li></ul></li><li><a href="#shen-du-xue-xi-tui-jian-xi-tong-de-qian-yan-shi-jian">深度学习推荐系统的前沿实践</a></li></ul></li><li><a href="#further">Further</a></li></ul></div><h2><span id="about">About</span><a href="#about" class="header-anchor"></a></h2><p>这是一篇对王喆的 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/35013197/">深度学习推荐系统</a> 的阅读笔记，其中会结合着工作相关的思考展开一些话题。</p><p>** 相关链接：**<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/wangzhenotes">王喆的机器学习笔记 - 知乎</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/138446984">《深度学习推荐系统》总结系列一 - 知乎</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/140894123">《深度学习推荐系统》总结系列二 - 知乎</a></p><h2><span id="shen-du-xue-xi-tui-jian-xi-tong">《深度学习推荐系统》</span><a href="#shen-du-xue-xi-tui-jian-xi-tong" class="header-anchor"></a></h2><h3><span id="tui-jian-xi-tong-de-ji-zhu-jia-gou">推荐系统的技术架构</span><a href="#tui-jian-xi-tong-de-ji-zhu-jia-gou" class="header-anchor"></a></h3><p>在获知用户信息、物品信息、场景信息的基础上，推荐系统要处理的问题可以形式化地定义为：对于用户 U（User）在特定场景 C（Context）下，针对海量物品信息 I（Item），构建一个函数 f(U,I,C), 预测用户对特定候选物品 I （Item）的喜好程度，再根据喜好程度对所有候选物品进行排序，生成推荐列表的问题。</p><p><img src="https://picb.zhimg.com/80/v2-b866ebb2408aea3e7e7373726b73a132_1440w.jpg"></p><p>而实际场景中，还需要着着重解决的问题有：</p><ul><li>数据和信息相关的问题：用户、物品、场景信息分别是什么，如何存储、更新和处理。</li><li>推荐系统算法和模型相关的问题：如何训练（training）、评估（evaluation）、部署（deployment）、线上推断（online inference）、从而达到更好的效果</li></ul><p><img src="https://pic4.zhimg.com/80/v2-b894ffb412a97f719917d1c7a4bea536_1440w.jpg"></p><p>在拿到推荐系统的原始数据之后，推荐系统会进一步加工，数据出口有三个</p><ol><li>生成推荐模型锁需要的样本数据，用于算法模型的训练和评估</li><li>生成推荐模型服务（model serving）所需的「特征」，用于推荐系统的线上推断</li><li>生成系统监控、商业智能（Business Intelligence，BI）所需的统计数据</li></ol><p>推荐系统「模型部分」是推荐系统的主题，一般由「召回层」「排序」「补充策略与算法层」组成。</p><ul><li>召回层：利用高效的召回规则、算法或简单模型，快速从海量的候选集召回用户可能感兴趣的物品</li><li>排序层：利用排序模型对初筛的候选集进行精排序</li><li>补充策略与算法：也被称为再排序层，在推荐列表返回用户之前，兼顾结果的多样性、流行度、新鲜度等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐里列表。</li></ul><h3><span id="tui-jian-xi-tong-de-jin-hua">推荐系统的进化</span><a href="#tui-jian-xi-tong-de-jin-hua" class="header-anchor"></a></h3><p>传统推荐模型的发展主要经历了四个阶段：</p><ul><li>** 协同过滤 CF 算法阶段 **：只需用户物品共现矩阵就可以构建推荐系统，根据相似度取值对象可分为 itemCF 和 userCF 两类，优势是简单易实现。CF 的问题是泛化能力弱，无法应对稀疏矩阵，而矩阵分解作为协同过滤的进化版，克服了 CF 的缺点。</li><li>** 逻辑回归 LR 阶段 **：综合利用用户、物品、上下文等多种不同的特征，假设用户是否点击广告服从伯努利分布，将推荐问题转化为点击率预估 (CTR) 问题，预测正样本概率对物品进行排序。其数学形式是各个特征的加权和经过 sigmoid 函数，得到用户点击物品的概率。LR 的优势是可解释性强、易于并行化、模型简单、训练开销小。其局限性在于表达能力不强，需要大量具有业务背景知识的人工特征筛选与交叉。</li><li>** 因子分解机 FM 阶段 *<em>：为每个特征学习一个隐向量，在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。虽然 FM 相比 POLY2 的完全交叉 + 单一权重记忆能力略弱，但解决了特征交叉过程中交叉特征对应的数据过于稀疏无法充分学习权重的问题。FFM 引入特征域进一步增强了模型的表达能力，做特征交叉时，每个特征选择与对方域对应的隐向量的内积作为交叉特征的权重，但 FFM 的计算复杂度也由 kn 上升到 kn</em>n。</li><li>** 组合模型阶段 **：这一阶段主要是为了进一步提高特征交叉的维度，同时融合多个模型的优点。GBDT+LR 是组合模型的代表方案，GBDT 自动进行特征筛选和组合得到新的离散特征向量输入 LR 模型。GBDT+LR 的组合方式开启了特征工程模型化的趋势，真正实现端到端训练。</li></ul><p><img src="https://picb.zhimg.com/80/v2-3018cb8019e5dba2b2592fd244d6c916_1440w.jpg"></p><h3><span id="shen-du-xue-xi-zai-tui-jian-xi-tong-zhong-de-ying-yong">深度学习在推荐系统中的应用</span><a href="#shen-du-xue-xi-zai-tui-jian-xi-tong-zhong-de-ying-yong" class="header-anchor"></a></h3><p>推荐系统模型经过了机器学习阶段充分的发展后，终于进入了深度学习时代。与传统机器学习模型相比，深度学习模型具有表达能力更强，模型结构更灵活更贴合业务场景的优点。</p><p>深度学习阶段的推荐模型从多层感知机 MLP 出发，通过改变神经网络的结构，演变为各种各样的深度学习推荐模型。总结起来，有七个演变方向：</p><ul><li>改变神经网络的复杂程度：增加深度神经网络的层数和结构复杂度。</li><li>丰富特征交叉方式：改变特征向量的交叉方式，如 NeuralCF，PNN(Product-based Neural Network)。</li><li>组合模型：组合两种不同特点、优势互补的网络，主要是指 Wide&amp;Deep 及其后续各种改进模型如 Deep&amp;Cross、DeepFM 等。</li><li>FM 模型的深度学习演化：对 FM 模型的各种改进，包括 NFM(Neural Factorization Machine) 使用神经网络提升 FM 二阶交叉部分的特征交叉能力、FNN(Factorization-machine supported Neural Network) 利用 FM 的结果进行网络初始化、AFM(Attention neural Factorization Machine) 在 FM 中引入注意力机制。</li><li>引入注意力机制：主要包括上述的 AFM 和 DIN(Deep Interest Network， 深度兴趣网络) 模型</li><li>融合序列模型：使用序列模型模拟用户行为或用户兴趣的演化趋势，如 DIEN(Deep Interest Evolution Network，深度兴趣进化网络)</li><li>结合强化学习：主要是为了模型的在线学习和实时更新，包括 DRN(Deep Reinforcement Learning Network, 深度强化学习网络)<br>首先直接在 DNN 上演变的模型有：</li></ul><p>AutoRec：将自编码器 (AutoEncoder) 与协同过滤结合的单隐层神经网络模型，利用协同过滤中的共现矩阵，完成物品 &#x2F; 用户向量的自编码，基于自编码的结果得到用户对物品的预估评分，进而排序。AutoRec 模型结构和 word2vec 结构一致，相对简单，但优化目标和训练方法有所不同，AutoRec 表达能力有限。<br>Deep Crossing：由微软于 2016 年发布，用于其搜索引擎 Bing 中的搜索广告推荐场景。Deep Crossing 完善了深度学习在推荐领域的实际应用流程，提出了一套完整的从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合的解决方案，开启了无需任何人工特征工程的时代</p><h3><span id="embedding-ji-zhu-zai-tui-jian-xi-tong-zhong-de-ying-yong">Embedding 技术在推荐系统中的应用</span><a href="#embedding-ji-zhu-zai-tui-jian-xi-tong-zhong-de-ying-yong" class="header-anchor"></a></h3><p>Embedding 是用一个低维稠密的向量来「表示」一个对象（object），向量能表达相应对象的某些特征，同时向量之间的距离也表示了物品之间的相似性。</p><p>为什么 Embedding 技术对深度学习如此重要 ？</p><ol><li>推荐系统中大量使用 one-hot 编码对类别、id 型特征进行编码，导致样本特征向量极度稀疏，而深度学习的结构特点使其不利于稀疏特征向量的处理，因此几乎所有的深度学习推荐模型都会由 Embedding 层负责将高维稀疏特征向量转成稠密低维特征向量。</li><li>Embedding 本身就是极其重要的特征向量，其表达能力更强。</li><li>Embedding 对物品、用户相似度的计算是常用的推荐系统召回层技术。在局部敏感哈希（Locality-Sensitive Hashing）等快速最近邻搜索技术应用于推荐系统之后，Embedding 更适用于对海量备选物品进行快速初步筛选，过滤出几百到几千的物品交由深度学习网络进行精排。</li></ol><p>所以，Embedding 非常重要，熟悉并掌握各类流行的 Embedding 方法是构建一个成功的深度学习推荐系统的有力武器。</p><h4><span id="word2vec-jing-dian-de-embedding-fang-fa">Word2vec，经典的 Embedding 方法</span><a href="#word2vec-jing-dian-de-embedding-fang-fa" class="header-anchor"></a></h4><p>word2vec（word to vevtor）是一个生成树词的向量表达模型。</p><h4><span id="item2vec">Item2vec</span><a href="#item2vec" class="header-anchor"></a></h4><h4><span id="graph-embedding">Graph Embedding</span><a href="#graph-embedding" class="header-anchor"></a></h4><p>Graph Embedding 是一种对图结构中的节点进行 Embedding 编码的方法。</p><p>links:</p><ul><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67218758">Embedding 在深度推荐系统中的 3 大应用方向 - 知乎</a></li><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/64200072">深度学习中不得不学的 Graph Embedding 方法 - 知乎</a></li><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53194407">万物皆 Embedding，从经典的 word2vec 到深度学习基本操作 item2vec - 知乎</a></li><li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/57313656">Airbnb 如何解决 Embedding 的数据稀疏问题？ - 知乎</a></li></ul><h3><span id="duo-jiao-du-shen-shi-tui-jian-xi-tong">多角度审视推荐系统</span><a href="#duo-jiao-du-shen-shi-tui-jian-xi-tong" class="header-anchor"></a></h3><h4><span id="te-zheng-gong-cheng">特征工程</span><a href="#te-zheng-gong-cheng" class="header-anchor"></a></h4><p>推荐系统中，特征的本质其实是对某个行为过程相关信息的抽象表达。从具体的行为转化为抽象的特征，这一过程必然涉及信息的损失。所以构建推荐系统特征工程的原则是：尽可能让特征工程抽取出的一组特征能够保留推荐环境以及用户行为过程中的有用信息，尽量摒弃冗余信息。</p><p>推荐系统的常用特征包括：</p><ol><li>** 用户行为数据 **,</li><li>** 用户关系数据 **，</li><li>** 属性、标签类数据 **</li><li>** 内容类数据 **，一般来说，内容类数据无法直接换换成推荐系统可以 “消化” 的特征，需要通过自然语言处理、计算机视觉等技术手段提取关键内容特征，再输入推荐系统。</li><li>** 上下文信息 **，描述推荐行为产生的场景信息，比如时间地点、季节、月份、是否是节假日、天气、空气质量、社会事件等。典型的例子是，用户可能会倾向于在特定时段看不同题材的电影。</li><li>** 统计类特征 **，即通过统计方法计算出的特征，例如历史 CTR、历史 CVR、物品热门程度、物品流程程度等。</li><li>** 组合特征 **，将不同的特征进行组合后生成的细腻特征，最常见的是年龄 + 性别组成的人口属性分段特征。</li></ol><p>这里有一篇有趣的文章，讲了特征的组合和特征值的重要性，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65475550">毕加索的「公牛」和机器学习的「特征工程」 - 知乎</a></p><p>对推荐系统来说，模型的输入往往是由数字组成的特征向量。在众多特征类别中，有年龄、播放时长、历史 CTR 这些可以由数字表达的特征，它们可以非常自然地成为特征向量中的一个维度。而对于更多的特征，如用户性别、观看历史，它们是如果转变成数值型特征向量的呢。</p><ol><li>** 连续性特征 **，如用户年龄、统计类特征、物品的发布时间、影片播放时长等数值型的特征，最常用的数据手段是归一化<br>、离散化、加非线性函数等方法。</li><li>** 类别型特征 **，如用户历史行为数据、属性标签类数据。它的原始表现性似乎还往往是一个类别或者一个 id，这类特征最常用的处理方法是使用 one-hot 编码将其转换成一个数值向量，面对同一个特征域非唯一的类别选项，还可以采用 multi-hot 编码。</li></ol><h4><span id="zhao-hui-ceng-he-pai-xu">召回层和排序</span><a href="#zhao-hui-ceng-he-pai-xu" class="header-anchor"></a></h4><p>召回阶段负责将海量的候选集快速缩小为几百到几千的规模；而排序阶段负责对缩小后的候选集进行精准排序。利用少量的特征和简单的模型或者规则进行候选集的快速筛选，减少精排阶段的时间开销。总结起来，召回和排序的特点为：</p><ul><li>召回层：计算量候选集大、速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能被快速召回，保证相关物品的召回率</li><li>排序层：目标是得到精准的排序，需处理的物品数量少，可利用特征多，使用比较复杂的模型。</li></ul><p>在权衡计算速度和召回率后，目前工业界主流的召回方法是采用多个简单策略叠加的「多路召回策略」。所谓多路召回，就是采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。在此过程中，候选集大小和策略选择都需要人工参与，策略之间的信息也是割裂的，无法综合考虑不同策略对一个物品的影响。</p><p>基于 Embedding 的召回是一个综合性更强且计算速度也能满足需求的召回方法。（TODO，后续可以展开）</p><h4><span id="parameter-server">Parameter Server</span><a href="#parameter-server" class="header-anchor"></a></h4><p>Reference: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/82116922">一文读懂「Parameter Server」的分布式机器学习训练原理</a></p><p>PS 分为两大部分：server group 和多个 worker group，另外 resource manager 负责总体的资源分配调度。</p><ul><li>server 节点的主要功能是保存模型参数、接受 worker 节点计算出的局部梯度、汇总计算全局梯度，并更新模型参数。server group 内部包含多个 server node，每个 server node 负责维护一部分参数，server manager 负责维护和分配 server 资源；</li><li>worker 节点的主要功能是各保存部分训练数据，从 server 节点拉取最新的模型参数，根据训练数据计算局部梯度，上传给 server 节点。每个 worker group 对应一个 application（即一个模型训练任务），worker group 之间，以及 worker group 内部的 worker node 互相之间并不通信，worker node 只与 server 通信。</li></ul><p>push：worker 节点利用本节点上的训练数据，计算好局部梯度，上传给 server 节点；<br>pull：为了进行下一轮的梯度计算，worker 节点从 server 节点拉取最新的模型参数到本地。<br>结合图 3 这里概括一下整个 PS 的分布式训练流程：</p><ul><li>每个 worker 载入一部分训练数据</li><li>worker 节点从 server 节点 pull 最新的全部模型参数</li><li>worker 节点利用本节点数据计算梯度</li><li>worker 节点将梯度 push 到 server 节点</li><li>server 节点汇总梯度更新模型</li><li>goto step2 直到迭代次数上限或模型收敛</li></ul><p>总结一下 Parameter Server 实现分布式机器学习模型训练的要点：</p><ul><li>用异步非阻断式的分布式梯度下降策略替代同步阻断式的梯度下降策略；</li><li>实现多 server 节点的架构，避免了单 master 节点带来的带宽瓶颈和内存瓶颈；</li><li>使用一致性哈希，range pull 和 range push 等工程手段实现信息的最小传递，避免广播操作带来的全局性网络阻塞和带宽浪费。</li></ul><p>但是，Parameter Server 仅仅是一个管理并行训练梯度的权重的平台，并不涉及到具体的模型实现，因此 PS 往往是作为 MXNet，TensorFlow 的一个组件，要想具体实现一个机器学习模型，还需要依赖于通用的，综合性的机器学习平台。</p><h4><span id="ru-he-zeng-jia-shi-shi-xing">如何增加实时性</span><a href="#ru-he-zeng-jia-shi-shi-xing" class="header-anchor"></a></h4><p>Reference：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75597761">如何增强推荐系统模型更新的「实时性」？ - 知乎</a></p><p>与 “特征” 的实时性相比，推荐系统模型的实时性往往是从更全局的角度考虑问题。特征的实时性力图用更准确的特征描述一个人，从而让推荐系统给出更符合这个人的推荐结果。要发现这类全局性的数据变化，就需要更快地更新模型。而影响模型的实时性最重要的因素就是模型的训练方式。</p><p>** 全量更新 **： 模型训练最常用的方式就是全量更新。模型会利用某时间段内的所有训练样本进行重新训练，再用训练好的新模型替代 “过时” 的模型。但全量更新需要训练的样本量大，因此所需训练时间较长；而且全量更新往往在离线的大数据平台上进行，如 spark+tensorflow，因此数据的延迟也较长，这都导致了全量更新是 “实时性” 最差的模型更新方式。</p><p>** 增量更新（Incremental Learning）**：增量更新仅将新加入的样本喂入模型进行增量学习。在实际的推荐系统中，往往采用增量更新与全局更新相结合的方式，在进行几轮增量更新后，在业务量较小的时间窗口进行全局更新，纠正模型在增量更新过程后中积累的误差。在 “实时性” 和 “全局最优” 中间进行取舍和权衡。</p><p>** 在线学习（online learning）**“增量更新” 是在获得一批新样本时进行增量更新，而在线学习是在每次获得一个新样本的时候就实时更新模型。</p><p>** 模型局部更新 **： 提高模型实时性的另外一个改进方向是进行模型的局部更新，大致的思路是降低训练效率低的部分的更新频率，提高训练效率高的部分的更新频率。这种方式比较有代表性的是 facebook 的 GBDT+LR 模型。</p><p>** 客户端模型实时更新：** 既然客户端是最接近用户的部分，实时性最强，那么能否在客户端就根据当前用户的行为历史更新模型呢？对于物品 embedding 的更新来说，往往需要全局的数据，因此只能在服务器端进行整体的更新；而对用户 embedding 来说，则更多依赖于用户自身的数据。那么把用户 embedding 的更新过程移植到客户端来做，就能够实时地把用户最近的行为数据反应到用户的 embedding 中来，从而通过实时改变用户 embedding 的方式完成实时推荐。</p><h3><span id="tui-jian-xi-tong-de-ping-gu">推荐系统的评估</span><a href="#tui-jian-xi-tong-de-ping-gu" class="header-anchor"></a></h3><h4><span id="netflix-tui-jian-xi-tong-mo-xing-de-kuai-su-xian-shang-ping-gu-fang-fa-interleaving"></span><a href="#netflix-tui-jian-xi-tong-mo-xing-de-kuai-su-xian-shang-ping-gu-fang-fa-interleaving" class="header-anchor"></a></h4><p>线上 AB Test 必然要占用宝贵的线上流量资源，还有可能会对用户体验造成损害，但线上流量资源显然是有限的，而且只有小部分能够用于 AB Test；而算法研发这侧，算法驱动的使用场景不断增加，大量候选算法需要逐一进行 AB Test。这二者之间的矛盾必然愈演愈烈。这就迫切需要设计一个快速的线上评估方法。</p><p>Netflix 设计了一个两阶段的线上测试过程（如图 2）。</p><ul><li>第一阶段利用被称为 Interleaving 的测试方法进行候选算法的快速筛选，从大量初始想法中筛选出少量 “优秀的”Ranking 算法。</li><li>第二阶段是对缩小的算法集合进行传统的 AB Test，以测量它们对用户行为的长期影响。</li></ul><p>传统 ab 测试的问题：<br>设计一个 AB Test 来验证用户群体是否对 “可口可乐” 和 “百事可乐” 存在口味倾向。那么按照传统的做法，我们会将测试人群随机分成两组然后进行 “盲测”，即在不告知可乐品牌的情况下进行测试。第一组只提供可口可乐，第二组只提供百事可乐，然后根据大家一定时间内的可乐消耗量来观察人们是更喜欢 “可口可乐” 还是 “百事可乐”。</p><p>这个实验一般意义上确实是有效的，很多时候我们也是这么做的。但也确实存在一些潜在的问题：</p><p>总的测试人群中，对于可乐的消费习惯肯定各不相同，从几乎不喝可乐到每天喝大量可乐的人都有。<br>可乐的重消费人群肯定只占总测试人群的一小部分，但他们可能占整体汽水消费的较大比例。<br>这两个问题导致了，即使 AB 两组之间重度可乐消费者的微小不平衡也可能对结论产生不成比例的影响。</p><p>在互联网场景下，这样的问题同样存在。比如 Netflix 场景下，非常活跃用户的数量是少数，但其贡献的观看时长却占较大的比例，因此 Netflix AB Test 中活跃用户被分在 A 组的多还是被分在 B 组的多，将对结果产生较大影响，从而掩盖模型的真实效果。</p><p>那么如何解决这个问题呢？一个方法是不对测试人群进行分组，而是让所有测试者都可以自由选择百事可乐和可口可乐（测试过程中仍没有品牌标签，但能区分是两种不同的可乐）。在实验结束时，统计每个人可口可乐和百事可乐的消费比例，然后进行平均后得到整体的消费比例。</p><p>这个测试方案的优点在于：</p><ul><li>消除了 AB 组测试者自身属性分布不均的问题；</li><li>通过给予每个人相同的权重，降低了重度消费者对结果的过多影响。</li></ul><p>这个测试思路应用于 Netflix 的场景，就是 Interleaving。Interleaving 是一种强大快捷的算法验证方法，它加速了 Netflix 各类 Ranking 算法的迭代创新。</p><p>但我们也要清楚的是 Interleaving 方法也存在一定的局限性，主要是下面两点：</p><ul><li>工程实现的框架较传统 AB Test 复杂。由于 Interleaving 实验的逻辑和业务逻辑纠缠在一起，因此业务逻辑可能会被干扰。而且为了实现 Interleaving，需要将大量辅助性的数据标示添加到整个数据 pipeline 中，这都是工程实现的难点；</li><li>Interleaving 毕竟只是对用户对算法推荐结果偏好程度的相对测量，不能得出一个算法完整的表现。比如我们想知道算法 A 能够将用户整体的观看时长提高多少，使用 Interleaving 是无法得出这样的结论的。为此 Netflix 才设计了 Interleaving+AB Test 两级实验结构，完善整个线上测试的框架。</li></ul><p><img src="https://pic4.zhimg.com/v2-366525b613a259d50a3c5e1abfd57d6d_1440w.jpg?source=172ae18b"></p><h3><span id="shen-du-xue-xi-tui-jian-xi-tong-de-qian-yan-shi-jian">深度学习推荐系统的前沿实践</span><a href="#shen-du-xue-xi-tui-jian-xi-tong-de-qian-yan-shi-jian" class="header-anchor"></a></h3><h2><span id="further">Further</span><a href="#further" class="header-anchor"></a></h2><p>后续思考和疑问</p><ul><li>one-hot, multi-hot</li><li>Explainable Recommend system</li></ul><div class="post__prevs"><div class="post__prev"><a href="/2020/06/30/2020-June-digest/" title="2020 年 6 月摘要"><i class="iconfont icon-prev"></i>2020 年 6 月摘要</a></div><div class="post__prev post__prev--right"><a href="/2020/07/31/2020-July-digest/" title="2020 年 7 月摘要">2020 年 7 月摘要<i class="iconfont icon-next"></i></a></div></div></div></article><div id="disqus_thread"></div></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">Fledgling Developer | Backpacker | Doing all I can to be a better girl.</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/tech/">tech</a><span class="block-list-count">20</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/reading/">reading</a><span class="block-list-count">6</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/music/">music</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/life/">life</a><span class="block-list-count">37</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2022/09/30/2022-02-09-digest/" title="2022 年 2 ~ 9 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/194582186-ee38f13c-5d74-42e4-b1c1-90045c865a09.jpeg" alt="2022 年 2 ~ 9 月摘要"></div><div class="item__info"><h3 class="item__title">2022 年 2 ~ 9 月摘要</h3><span class="item__text">2022-09-30</span></div></a></li><li class="latest-post-item"><a href="/2022/01/31/2021-12-digest/" title="2021 年 12 月 & 1 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/152668876-eb16783b-8204-432e-9d98-17a9e5a9b510.jpeg" alt="2021 年 12 月 & 1 月摘要"></div><div class="item__info"><h3 class="item__title">2021 年 12 月 & 1 月摘要</h3><span class="item__text">2022-01-31</span></div></a></li><li class="latest-post-item"><a href="/2021/11/30/2021-11-digest/" title="2021 年 11 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/145077778-da1bc9f0-d052-423e-a8a2-4128c1fe12ee.jpeg" alt="2021 年 11 月摘要"></div><div class="item__info"><h3 class="item__title">2021 年 11 月摘要</h3><span class="item__text">2021-11-30</span></div></a></li><li class="latest-post-item"><a href="/2021/10/31/2021-10-digest/" title="2021 年 10 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/140796892-d61c5310-8b08-49bd-955f-7d1f36ed8458.jpeg" alt="2021 年 10 月摘要"></div><div class="item__info"><h3 class="item__title">2021 年 10 月摘要</h3><span class="item__text">2021-10-31</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-item"><a class="tag-link" href="/tags/code-reading/">code_reading</a></li><li class="tag-item"><a class="tag-link" href="/tags/cookbook/">cookbook</a></li><li class="tag-item"><a class="tag-link" href="/tags/digest/">digest</a></li><li class="tag-item"><a class="tag-link" href="/tags/life/">life</a></li><li class="tag-item"><a class="tag-link" href="/tags/music-log/">music_log</a></li><li class="tag-item"><a class="tag-link" href="/tags/reading/">reading</a></li><li class="tag-item"><a class="tag-link" href="/tags/tech/">tech</a></li><li class="tag-item"><a class="tag-link" href="/tags/%E5%AE%9E%E9%AA%8C/">实验</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2018 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>, modified by <a href="https://github.com/AmyLewis" target="_blank">amy</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/AmyLewis" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="mailto:amylewis.private@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="/atom.xml" target="_blank" title="rss"><i class="iconfont icon-rss"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script>var disqus_shortname="amylewis777",disqus_config=function(){this.page.url="http://amylewis.github.io/2020/07/21/Rec_sys_book_reading/",this.page.identifier="/2020/07/21/Rec_sys_book_reading/",this.page.title="《深度学习推荐系统》阅读 WIP"};!function(){var e=document,t=e.createElement("script");t.src="https://"+disqus_shortname+".disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></body></html>