<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>Celery Cookbook | Amyy Lewis</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="life tech"><meta name="description" content="Fledgling Developer | Backpacker | Doing all I can to be a better girl."><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://amylewis.github.io/2018/12/18/celery-cookbook/index.html"><link rel="icon" type="image/png" href="http://oo12ugek5.bkt.clouddn.com/blog/images/favicon.ico" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="AmyLewis" type="application/atom+xml"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-66043212-2"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-66043212-2")</script><link rel="stylesheet" href="/scss/views/page/post.css"><meta name="generator" content="Hexo 6.3.0"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(https://user-images.githubusercontent.com/3325198/52893052-6d1d2d80-31d3-11e9-91c2-736385c3278a.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="AmyLewis" alt="AmyLewis"><img src="https://user-images.githubusercontent.com/3325198/52892707-fc284680-31cf-11e9-932d-e3cde3ef02f3.png" alt="AmyLewis"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="https://user-images.githubusercontent.com/3325198/52894275-f4719d80-31e1-11e9-905d-e4ffd271f045.jpeg" alt="Celery Cookbook"></div><header class="post__info"><h1 class="post__title">Celery Cookbook</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a target="_blank" rel="noopener" href="https://www.github.com/amylewis">amy</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2018-12-18</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/tech/">Tech</a></li><li class="mark__item"><a href="/tags/cookbook/">Cookbook</a></li></ul></div></div></header><div class="post__content"><p><strong>Table of content:</strong></p><div class="toc"><ul><li><a href="#about">About</a></li><li><a href="#celery-he-xin">Celery 核心</a><ul><li><a href="#bao-han-de-zu-jian">包含的组件</a><ul><li><a href="#celery-beat-ren-wu-diao-du-qi-todo">Celery Beat 任务调度器 (todo)</a></li><li><a href="#celery-worker-zhi-xing-ren-wu-de-xiao-fei-zhe">Celery Worker, 执行任务的消费者</a></li><li><a href="#broker-xiao-xi-dai-li">Broker 消息代理</a></li><li><a href="#producer-sheng-chan-zhe">Producer 生产者</a></li><li><a href="#result-backend-ren-wu-chu-li-wan-hou-bao-cun-zhuang-tai-xin-xi-he-jie-guo-yi-gong-cha-xun">Result Backend, 任务处理完后保存状态信息和结果，以供查询</a></li></ul></li><li><a href="#workflow">Workflow</a></li><li><a href="#he-qi-ta-ren-wu-dui-lie-de-bi-jiao-todo">和其他任务队列的比较(todo)</a></li></ul></li><li><a href="#zui-jia-shi-jian">最佳实践</a><ul><li><a href="#jin-liang-bu-yao-shi-yong-shu-ju-ku-zuo-wei-amqp-broker">尽量不要使用数据库作为 AMQP Broker</a></li><li><a href="#shi-yong-duo-ge-dui-lie-todo">使用多个队列 (todo)</a></li><li><a href="#ding-yi-ju-you-you-xian-ji-de-workers">定义具有优先级的 workers</a></li><li><a href="#shan-yong-ren-wu-gong-zuo-liu">善用任务工作流</a></li><li><a href="#shi-yong-celery-de-cuo-wu-chu-li-ji-zhi">使用 celery 的错误处理机制</a></li><li><a href="#bu-yao-jiang-database-orm-dui-xiang-chuan-ru-tasks">不要将 Database&#x2F;ORM 对象传入 tasks</a></li><li><a href="#she-zhi-task-chao-shi">设置 task 超时</a></li><li><a href="#jiang-da-xing-task-zuo-wei-lei">将大型 task 作为类</a></li><li><a href="#ren-wu-zhuang-tai-hui-diao">任务状态回调</a></li><li><a href="#she-zhi-worker-de-shu-liang">设置 worker 的数量</a></li><li><a href="#dan-yuan-ce-shi">单元测试</a></li><li><a href="#dui-yu-zhi-xing-shi-jian-chang-duan-bu-yi-de-ren-wu-jian-yi-kai-qi-ofair">对于执行时间长短不一的任务建议开启 -Ofair</a></li><li><a href="#qi-dong-ren-wu-jian-kong">启动任务监控</a></li></ul></li><li><a href="#shi-yong-chang-jing-he-chang-jian-wen-ti">使用场景和常见问题</a><ul><li><a href="#reserve-one-task-at-a-time-han-yi-shi-shi-me-todo">Reserve one task at a time 含义是什么 ？（todo）</a></li><li><a href="#deply-he-apply-async-de-qu-bie">deply 和 apply_async 的区别</a></li><li><a href="#worker-qi-dong-ri-zhi-li-mian-de-concurrency-x-prefork-han-yi-todo">worker 启动日志里面的 concurrency: x (prefork) 含义(todo)</a></li><li><a href="#worker-she-zhi-chao-shi-shi-jian-soft-time-limit-he-time-limit-qu-bie">worker 设置超时时间, Soft time limit 和 Time Limit 区别</a></li></ul></li><li><a href="#reference-recommendation">Reference &amp; Recommendation</a></li><li><a href="#geng-xin-ri-zhi">更新日志</a></li><li><a href="#guan-yu-tou-tu">关于头图</a></li></ul></div><h2><span id="about">About</span><a href="#about" class="header-anchor"></a></h2><p>Celery 是个分布式消息队列。简单，灵活，且可靠。这是一篇会持续更新并且会很长的文章，致力解决的问题：</p><ul><li>Celery 的架构和原理</li><li>一些核心概念</li><li>和其他消息队列的对比</li><li>结合自己使用和看书了解到的最佳实践</li><li>在 Celery 使用过程中遇到过的一些问题，使用场景，以及背后的原理</li></ul><p>不包括：</p><ul><li>Celery 的安装使用和常见功能介绍</li></ul><p>还会继续扩展或还有疑问的部分会被标记成 todo 。</p><h2><span id="celery-he-xin">Celery 核心</span><a href="#celery-he-xin" class="header-anchor"></a></h2><h3><span id="bao-han-de-zu-jian">包含的组件</span><a href="#bao-han-de-zu-jian" class="header-anchor"></a></h3><h4><span id="celery-beat-ren-wu-diao-du-qi-todo">Celery Beat 任务调度器 (todo)</span><a href="#celery-beat-ren-wu-diao-du-qi-todo" class="header-anchor"></a></h4><p>Beat 进程会读取配置文件的内容，周期性地将配置中到期需要执行的任务发送给任务队列</p><h4><span id="celery-worker-zhi-xing-ren-wu-de-xiao-fei-zhe">Celery Worker, 执行任务的消费者</span><a href="#celery-worker-zhi-xing-ren-wu-de-xiao-fei-zhe" class="header-anchor"></a></h4><p>通常会在多台服务器运行多个消费者来提高执行效率</p><h4><span id="broker-xiao-xi-dai-li">Broker 消息代理</span><a href="#broker-xiao-xi-dai-li" class="header-anchor"></a></h4><p>或者叫作消息中间件，接受任务生产者发送过来的任务消息，存进队列再按序分发给任务消费者 worker。</p><p>Broker 的选择大致有消息队列和数据库两种(这里建议尽量避免使用数据库作为 Broker，后文最佳实践中有提及）。</p><p>Celery 官方是推荐使用 RabbitMQ 来做 broker，有很多成功的案例。工业上，很多项目是使用 RabbitMQ 作为 Broker，Redis 用来存储结果。</p><p>todo: 对比 RabbitMQ 和 Redis</p><h4><span id="producer-sheng-chan-zhe">Producer 生产者</span><a href="#producer-sheng-chan-zhe" class="header-anchor"></a></h4><p>调用了 Celery 提供的 API、函数或者装饰器而产生任务并交给任务队列处理的都是任务生产者</p><h4><span id="result-backend-ren-wu-chu-li-wan-hou-bao-cun-zhuang-tai-xin-xi-he-jie-guo-yi-gong-cha-xun">Result Backend, 任务处理完后保存状态信息和结果，以供查询</span><a href="#result-backend-ren-wu-chu-li-wan-hou-bao-cun-zhuang-tai-xin-xi-he-jie-guo-yi-gong-cha-xun" class="header-anchor"></a></h4><p>Celery 默认已支持 Redis、RabbitMQ、MongoDB、Django ORM、SQLAlchemy 等方式</p><h3><span id="workflow">Workflow</span><a href="#workflow" class="header-anchor"></a></h3><h3><span id="he-qi-ta-ren-wu-dui-lie-de-bi-jiao-todo">和其他任务队列的比较(todo)</span><a href="#he-qi-ta-ren-wu-dui-lie-de-bi-jiao-todo" class="header-anchor"></a></h3><p>轻量级的替代方案：<br>RQ: Simple job queues for Python <a target="_blank" rel="noopener" href="http://python-rq.org/">http://python-rq.org/</a></p><p>一个更加复杂完善，但是原理不同<br>Pyro - Python Remote Objects - 4.60 — Pyro 4.60 documentation <a target="_blank" rel="noopener" href="https://pythonhosted.org/Pyro4/">https://pythonhosted.org/Pyro4/</a></p><h2><span id="zui-jia-shi-jian">最佳实践</span><a href="#zui-jia-shi-jian" class="header-anchor"></a></h2><h3><span id="jin-liang-bu-yao-shi-yong-shu-ju-ku-zuo-wei-amqp-broker">尽量不要使用数据库作为 AMQP Broker</span><a href="#jin-liang-bu-yao-shi-yong-shu-ju-ku-zuo-wei-amqp-broker" class="header-anchor"></a></h3><p>Broker 的选择大致有消息队列和数据库两种，这里建议尽量避免使用数据库作为 Broker，除非你的业务系统足够简单。</p><p>在并发量很高的复杂系统中，大量 Workers 访问数据库的行为会使得操作系统磁盘 I&#x2F;O 一直处于高峰值状态，非常影响系统性能。如果数据库 Broker 同时还兼顾着后端业务的话，那么应用程序也很容易被拖垮。</p><p>反观选择消息队列，例如 RabbitMQ，就不存在以上的问题。首先 RabbitMQ 的队列存放到内存中，速度快且不占用磁盘 I&#x2F;O。再一个就是 RabbitMQ 会主动将任务推送给 Worker，所以 Worker 无需频繁的去轮询队列，避免无谓的资源浪费。</p><p>todo: RabbitMQ 和其他 Broker 的对比结果</p><h3><span id="shi-yong-duo-ge-dui-lie-todo">使用多个队列 (todo)</span><a href="#shi-yong-duo-ge-dui-lie-todo" class="header-anchor"></a></h3><p>对于不同的 task ，尽量使用不同的队列来处理。以下是一个简化模型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@app.task()</span><br><span class="line">def my_taskA(a, b, c):</span><br><span class="line">	print(&quot;doing something here...&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.task()</span><br><span class="line">def my_taskB(x, y):</span><br><span class="line">	print(&quot;doing something here...&quot;)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task_queues=(</span><br><span class="line">    Queue(&#x27;default&#x27;, routing_key=&#x27;default&#x27;),</span><br><span class="line">    Queue(&#x27;other&#x27;, routing_key=&#x27;other&#x27;),</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@app.task(queue=&#x27;other&#x27;)</span><br><span class="line">def parse_something():</span><br><span class="line">  	pass</span><br></pre></td></tr></table></figure><h3><span id="ding-yi-ju-you-you-xian-ji-de-workers">定义具有优先级的 workers</span><a href="#ding-yi-ju-you-you-xian-ji-de-workers" class="header-anchor"></a></h3><h3><span id="shan-yong-ren-wu-gong-zuo-liu">善用任务工作流</span><a href="#shan-yong-ren-wu-gong-zuo-liu" class="header-anchor"></a></h3><p>Celery 支持 group&#x2F;chain&#x2F;chord&#x2F;chunks&#x2F;map&#x2F;starmap 等多种工作流原语，基本可以覆盖大部分复杂的任务组合需求，善用任务工作流能够更好的应用 Celery 优秀的并发特性。</p><ul><li>chain, 下一步任务需要等待上一步任务的执行结果，或者任务是按顺序串行的情况</li><li>chord</li></ul><p>例如，如果下一步任务需要等待上一步任务的执行结果，那么不应该单纯的应用 get 方法来实现同步子任务，而是应该使用 chain 任务链。</p><p>尽量不要以同步阻塞的方式调用子任务，而是用异步回调的方式进行链式任务的调用, 比如以下的例子：</p><ul><li>update_page_info, 正确方式，平均耗时 252.3190975189209</li><li>update_page_info_01, 错误示范，平均耗时 3129.5740604400635</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def update_page_info(url):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    上一个 Task 的返回作为下一个 Task 的输出</span><br><span class="line">    fetch_page -&gt; parse_page -&gt; store_page</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)</span><br><span class="line">    chain()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def update_page_info_01(url):</span><br><span class="line">    page = fetch_page.delay(url).get()</span><br><span class="line">    info = parse_page.delay(page).get()</span><br><span class="line">    store_page_info.delay(info, url)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@app.task()</span><br><span class="line">def fetch_page(url):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print &quot;fetching page. url: &#123;&#125;&quot;.format(url)</span><br><span class="line">    return &#x27;&lt;html&gt;hello world&lt;/html&gt;&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.task()</span><br><span class="line">def parse_page(page):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print &quot;parsing page. page: &#123;&#125;&quot;.format(page)</span><br><span class="line">    return &quot;parsed_content&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.task(ignore_result=True)</span><br><span class="line">def store_page_info(info, url):</span><br><span class="line">    print &quot;storing content, info: &#123;&#125;, url: &#123;&#125;&quot;.format(info, url)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print &#x27;done&#x27;</span><br></pre></td></tr></table></figure><h3><span id="shi-yong-celery-de-cuo-wu-chu-li-ji-zhi">使用 celery 的错误处理机制</span><a href="#shi-yong-celery-de-cuo-wu-chu-li-ji-zhi" class="header-anchor"></a></h3><h3><span id="bu-yao-jiang-database-x2f-orm-dui-xiang-chuan-ru-tasks">不要将 Database&#x2F;ORM 对象传入 tasks</span><a href="#bu-yao-jiang-database-x2f-orm-dui-xiang-chuan-ru-tasks" class="header-anchor"></a></h3><p>不应该讲 Database objects 比如一个 User Model 传入在后台执行的任务，因为这些 object 可能包含过期的数据。相反应该传入一个 user id ，让 task 在执行过程中向数据库请求全新的 User Object。</p><h3><span id="she-zhi-task-chao-shi">设置 task 超时</span><a href="#she-zhi-task-chao-shi" class="header-anchor"></a></h3><p>推荐设置一个全局的 Soft timeout 时间，再根据 Task 类型单独设置一些特别的，防止一些长时间运行的任务阻塞</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Add a one-minute timeout to all Celery tasks.</span><br><span class="line">CELERYD_TASK_SOFT_TIME_LIMIT = 60</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@app.task(soft_time_limit=5)</span><br><span class="line">def send_push_notification(device_token, message, data=None):</span><br><span class="line">  notification_json = build_notification_json(message, data=data)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><h3><span id="jiang-da-xing-task-zuo-wei-lei">将大型 task 作为类</span><a href="#jiang-da-xing-task-zuo-wei-lei" class="header-anchor"></a></h3><p>做一些统一的日志和错误日志等, 非常方便</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">from celery import Task</span><br><span class="line"></span><br><span class="line">from proj.celery import app</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyTask(Task):</span><br><span class="line">    def on_success(self, retval, task_id, args, kwargs):</span><br><span class="line">        print &#x27;task done: &#123;0&#125;&#x27;.format(retval)</span><br><span class="line">        return super(MyTask, self).on_success(retval, task_id, args, kwargs)</span><br><span class="line"></span><br><span class="line">    def on_failure(self, exc, task_id, args, kwargs, einfo):</span><br><span class="line">        print &#x27;task fail, reason: &#123;0&#125;&#x27;.format(exc)</span><br><span class="line">        return super(MyTask, self).on_failure(exc, task_id, args, kwargs, einfo)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.task(base=MyTask)</span><br><span class="line">def add(x, y):</span><br><span class="line">    return x + y</span><br></pre></td></tr></table></figure><h3><span id="ren-wu-zhuang-tai-hui-diao">任务状态回调</span><a href="#ren-wu-zhuang-tai-hui-diao" class="header-anchor"></a></h3><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">PENDING</td><td align="left">任务等待中</td></tr><tr><td align="left">STARTED</td><td align="left">任务已开始</td></tr><tr><td align="left">SUCCESS</td><td align="left">任务执行成功</td></tr><tr><td align="left">FAILURE</td><td align="left">任务执行失败</td></tr><tr><td align="left">RETRY</td><td align="left">任务将被重试</td></tr><tr><td align="left">REVOKED</td><td align="left">任务取消</td></tr></tbody></table><p>也就是可以通过新定义一个状态，在执行等待中获取。但是实测下来 on_message 在部分场景下是不支持的, 比如 Celery 版本和 broker 类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@app.task(bind=True)</span><br><span class="line">def test_mes(self):</span><br><span class="line">    for i in xrange(1, 11):</span><br><span class="line">        time.sleep(0.1)</span><br><span class="line">        self.update_state(state=&quot;PROGRESS&quot;, meta=&#123;&#x27;p&#x27;: i*10&#125;)</span><br><span class="line">    return &#x27;finish&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pm(body):</span><br><span class="line">    res = body.get(&#x27;result&#x27;)</span><br><span class="line">    if body.get(&#x27;status&#x27;) == &#x27;PROGRESS&#x27;:</span><br><span class="line">        sys.stdout.write(&#x27;\r任务进度: &#123;0&#125;%&#x27;.format(res.get(&#x27;p&#x27;)))</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">    else:</span><br><span class="line">        print &#x27;\r&#x27;</span><br><span class="line">        print res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">r = test_mes.delay()</span><br><span class="line">print r.get(on_message=pm, propagate=False)</span><br></pre></td></tr></table></figure><h3><span id="she-zhi-worker-de-shu-liang">设置 worker 的数量</span><a href="#she-zhi-worker-de-shu-liang" class="header-anchor"></a></h3><p>Celery 默认会开启和 CPU core 一样数量的 worker，如果想要不想开启多个 worker ，可以通过启动时指定 –concurrency 选项</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--concurrency=1</span><br></pre></td></tr></table></figure><h3><span id="dan-yuan-ce-shi">单元测试</span><a href="#dan-yuan-ce-shi" class="header-anchor"></a></h3><p>直接调用 worker task 中的方法，不要使用 task.delay() 。 或者使用 Eager Mode，使用 task_always_eager 设置来启用，当启用该选项之后，task 会立即被调用。而这两种方式都只能测试 task worker 中的内容，官方并不建议这么做。</p><p>官方文档在 task_always_eager 里面的描述是：<br>If this is True, all tasks will be executed locally by blocking until the task returns. apply_async() and Task.delay() will return an EagerResult instance, that emulates the API and behavior of AsyncResult, except the result is already evaluated.</p><p>That is, tasks will be executed locally instead of being sent to the queue.</p><ul><li>Testing with Celery — Celery 4.2.0 documentation <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/userguide/testing.html">http://docs.celeryproject.org/en/latest/userguide/testing.html</a></li><li>task_always_eager <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/userguide/configuration.html#std:setting-task_always_eager">http://docs.celeryproject.org/en/latest/userguide/configuration.html#std:setting-task_always_eager</a></li></ul><h3><span id="dui-yu-zhi-xing-shi-jian-chang-duan-bu-yi-de-ren-wu-jian-yi-kai-qi-ofair">对于执行时间长短不一的任务建议开启 -Ofair</span><a href="#dui-yu-zhi-xing-shi-jian-chang-duan-bu-yi-de-ren-wu-jian-yi-kai-qi-ofair" class="header-anchor"></a></h3><p>用 <a target="_blank" rel="noopener" href="https://medium.com/@taylorhughes/three-quick-tips-from-two-years-with-celery-c05ff9d7f9eb">文章</a> 里面的图片能非常快速说明问题<br><img src="https://cdn-images-1.medium.com/max/2000/1*-PuCPUfqydGcRXle54SfxA.png"></p><p>也就是说 Celery 默认会平均分配任务给 worker，不管当前 worker 是否繁忙。如果如果任务的时间差别非常大时，就比较明显了。在启动命令里面加上 <code>-Ofair</code> 可以关闭这样的特性。</p><p>这样做会带来一些调度上的开销，但是整个行为会好预测很多。</p><p>Ref:</p><ul><li>Optimizing — Celery 4.2.0 documentation <a target="_blank" rel="noopener" href="https://celery.readthedocs.io/en/latest/userguide/optimizing.html#prefork-pool-prefetch-settings">https://celery.readthedocs.io/en/latest/userguide/optimizing.html#prefork-pool-prefetch-settings</a></li></ul><h3><span id="qi-dong-ren-wu-jian-kong">启动任务监控</span><a href="#qi-dong-ren-wu-jian-kong" class="header-anchor"></a></h3><p>Flower 是 Celery 官方推荐的实时监控工具，用于监控 Tasks 和 Workers 的运行状态。Flower 提供了下列功能：</p><ul><li>查看 Task 清单、历史记录、参数、开始时间、执行状态等</li><li>撤销、终止任务</li><li>查看 Worker 清单、状态</li><li>远程开启、关闭、重启 Worker 进程</li><li>提供 HTTP API，方便集成到运维系统</li><li>相比查看日志，Flower 的 Web 界面会显得更加友好。</li></ul><h2><span id="shi-yong-chang-jing-he-chang-jian-wen-ti">使用场景和常见问题</span><a href="#shi-yong-chang-jing-he-chang-jian-wen-ti" class="header-anchor"></a></h2><h3><span id="reserve-one-task-at-a-time-han-yi-shi-shi-me-todo">Reserve one task at a time 含义是什么 ？（todo）</span><a href="#reserve-one-task-at-a-time-han-yi-shi-shi-me-todo" class="header-anchor"></a></h3><p>在 <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/userguide/optimizing.html#reserve-one-task-at-a-time">文档</a></p><p>里面提到了一个优化思路</p><h3><span id="deply-he-apply-async-de-qu-bie">deply 和 apply_async 的区别</span><a href="#deply-he-apply-async-de-qu-bie" class="header-anchor"></a></h3><p>deply 是 apply_async 的一个快捷使用方式，</p><p>从 <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.apply_async">文档</a> 看到 apply_async 支持更多复杂的控制, 比如：</p><ul><li>重试次数，重试策略, 每次重试等待时间</li><li>expires, 任务过期时间</li><li>countdown, Number of seconds into the future that the task should execute, 默认为立刻执行</li><li>任务的队列，优先级</li></ul><p>Ref:</p><ul><li>delay &amp; apply_async <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#calling-the-task">http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#calling-the-task</a></li><li>apply_async API: <a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.apply_async">http://docs.celeryproject.org/en/latest/reference/celery.app.task.html#celery.app.task.Task.apply_async</a></li></ul><h3><span id="worker-qi-dong-ri-zhi-li-mian-de-concurrency-x-prefork-han-yi-todo">worker 启动日志里面的 concurrency: x (prefork) 含义(todo)</span><a href="#worker-qi-dong-ri-zhi-li-mian-de-concurrency-x-prefork-han-yi-todo" class="header-anchor"></a></h3><h3><span id="worker-she-zhi-chao-shi-shi-jian-soft-time-limit-he-time-limit-qu-bie">worker 设置超时时间, Soft time limit 和 Time Limit 区别</span><a href="#worker-she-zhi-chao-shi-shi-jian-soft-time-limit-he-time-limit-qu-bie" class="header-anchor"></a></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@app.task(bind=True, soft_time_limit=1, time_limit=3)</span><br><span class="line">def long_task(self):</span><br><span class="line">    try:</span><br><span class="line">        print &quot;your logic here&quot;</span><br><span class="line">    except SoftTimeLimitExceeded:</span><br><span class="line">        print &quot;clean up after soft limit&quot;</span><br></pre></td></tr></table></figure><p>超过设置的 soft limit 之后，会抛一个 SoftTimeLimitExceeded(), task 里面可以对这样的错误进行处理:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2018-12-17 00:12:43,267: WARNING/MainProcess] Soft time limit (1s) exceeded for task_name[task_id]</span><br></pre></td></tr></table></figure><p>但是如果是 hard time limit， worker 会被 kill 掉，任务也就会被强制结束，日志如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[2018-12-17 00:12:45,275: ERROR/MainProcess] Task task_name[task_id] raised unexpected: TimeLimitExceeded(3,)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/xxx/Library/Python/2.7/lib/python/site-packages/billiard/pool.py&quot;, line 645, in on_hard_timeout</span><br><span class="line">    raise TimeLimitExceeded(job._timeout)</span><br><span class="line">TimeLimitExceeded: TimeLimitExceeded(3,)</span><br><span class="line">[2018-12-17 00:12:45,275: ERROR/MainProcess] Hard time limit (3s) exceeded for task_name[task_id]</span><br><span class="line">[2018-12-17 00:12:45,379: ERROR/MainProcess] Process &#x27;Worker-3&#x27; pid:68973 exited with &#x27;signal 9 (SIGKILL)&#x27;</span><br></pre></td></tr></table></figure><p>Ref:</p><ul><li><a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/userguide/configuration.html#task-soft-time-limit">http://docs.celeryproject.org/en/latest/userguide/configuration.html#task-soft-time-limit</a></li><li><a target="_blank" rel="noopener" href="http://docs.celeryproject.org/en/latest/userguide/configuration.html#task-time-limit">http://docs.celeryproject.org/en/latest/userguide/configuration.html#task-time-limit</a></li></ul><h2><span id="reference-amp-recommendation">Reference &amp; Recommendation</span><a href="#reference-amp-recommendation" class="header-anchor"></a></h2><ul><li>Three quick tips from two years with Celery – Taylor Hughes – Medium <a target="_blank" rel="noopener" href="https://medium.com/@taylorhughes/three-quick-tips-from-two-years-with-celery-c05ff9d7f9eb">https://medium.com/@taylorhughes/three-quick-tips-from-two-years-with-celery-c05ff9d7f9eb</a></li><li>《Python分布式计算》 第4章 Celery分布式应用 （Distributed Comp… - 简书 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/ee14ed9e4989">https://www.jianshu.com/p/ee14ed9e4989</a></li><li>Deni Bertovic :: Celery - Best Practices <a target="_blank" rel="noopener" href="https://denibertovic.com/posts/celery-best-practices/">https://denibertovic.com/posts/celery-best-practices/</a></li><li>Celery 最佳实践 | Verne in GitHub <a target="_blank" rel="noopener" href="http://einverne.github.io/post/2017/05/celery-best-practice.html">http://einverne.github.io/post/2017/05/celery-best-practice.html</a></li><li>分布式队列神器 Celery | RaPoSpectre的个人博客 <a target="_blank" rel="noopener" href="https://www.rapospectre.com/blog/celery-user-guide">https://www.rapospectre.com/blog/celery-user-guide</a></li></ul><h2><span id="geng-xin-ri-zhi">更新日志</span><a href="#geng-xin-ri-zhi" class="header-anchor"></a></h2><ul><li>2018-12-18 根据自己的使用和理解，列了一些 Celery 的最佳实践和一些常见问题</li></ul><h2><span id="guan-yu-tou-tu">关于头图</span><a href="#guan-yu-tou-tu" class="header-anchor"></a></h2><p>拍摄自费城</p><div class="post__prevs"><div class="post__prev"><a href="/2018/12/09/2018-Nov-digest/" title="2018 年 11 月摘要"><i class="iconfont icon-prev"></i>2018 年 11 月摘要</a></div><div class="post__prev post__prev--right"><a href="/2018/12/31/2018-Dec-digest/" title="2018 年 12 月摘要">2018 年 12 月摘要<i class="iconfont icon-next"></i></a></div></div></div></article><div id="disqus_thread"></div></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">Fledgling Developer | Backpacker | Doing all I can to be a better girl.</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/tech/">tech</a><span class="block-list-count">20</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/reading/">reading</a><span class="block-list-count">6</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/music/">music</a><span class="block-list-count">8</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/life/">life</a><span class="block-list-count">38</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2023/08/31/2022-Oct-digest/" title="2022 年 10 月 ~ 2023 年 8 月"><div class="item__cover"><img src="https://github.com/AmyLewis/blog/assets/3325198/06d4024a-6a6e-4bf1-a3e4-575a1eba9389" alt="2022 年 10 月 ~ 2023 年 8 月"></div><div class="item__info"><h3 class="item__title">2022 年 10 月 ~ 2023 年 8 月</h3><span class="item__text">2023-08-31</span></div></a></li><li class="latest-post-item"><a href="/2022/09/30/2022-02-09-digest/" title="2022 年 2 ~ 9 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/194582186-ee38f13c-5d74-42e4-b1c1-90045c865a09.jpeg" alt="2022 年 2 ~ 9 月摘要"></div><div class="item__info"><h3 class="item__title">2022 年 2 ~ 9 月摘要</h3><span class="item__text">2022-09-30</span></div></a></li><li class="latest-post-item"><a href="/2022/01/31/2021-12-digest/" title="2021 年 12 月 & 1 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/152668876-eb16783b-8204-432e-9d98-17a9e5a9b510.jpeg" alt="2021 年 12 月 & 1 月摘要"></div><div class="item__info"><h3 class="item__title">2021 年 12 月 & 1 月摘要</h3><span class="item__text">2022-01-31</span></div></a></li><li class="latest-post-item"><a href="/2021/11/30/2021-11-digest/" title="2021 年 11 月摘要"><div class="item__cover"><img src="https://user-images.githubusercontent.com/3325198/145077778-da1bc9f0-d052-423e-a8a2-4128c1fe12ee.jpeg" alt="2021 年 11 月摘要"></div><div class="item__info"><h3 class="item__title">2021 年 11 月摘要</h3><span class="item__text">2021-11-30</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-item"><a class="tag-link" href="/tags/code-reading/">code_reading</a></li><li class="tag-item"><a class="tag-link" href="/tags/cookbook/">cookbook</a></li><li class="tag-item"><a class="tag-link" href="/tags/digest/">digest</a></li><li class="tag-item"><a class="tag-link" href="/tags/life/">life</a></li><li class="tag-item"><a class="tag-link" href="/tags/music-log/">music_log</a></li><li class="tag-item"><a class="tag-link" href="/tags/reading/">reading</a></li><li class="tag-item"><a class="tag-link" href="/tags/tech/">tech</a></li><li class="tag-item"><a class="tag-link" href="/tags/%E5%AE%9E%E9%AA%8C/">实验</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2018 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>, modified by <a href="https://github.com/AmyLewis" target="_blank">amy</a></p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/AmyLewis" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="mailto:amylewis.private@gmail.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="/atom.xml" target="_blank" title="rss"><i class="iconfont icon-rss"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script>var disqus_shortname="amylewis777",disqus_config=function(){this.page.url="http://amylewis.github.io/2018/12/18/celery-cookbook/",this.page.identifier="/2018/12/18/celery-cookbook/",this.page.title="Celery Cookbook"};!function(){var e=document,t=e.createElement("script");t.src="https://"+disqus_shortname+".disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></body></html>